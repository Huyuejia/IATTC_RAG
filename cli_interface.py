"""
æµ·æ´‹æ¸”ä¸šè°ˆåˆ¤è¾…åŠ©RAGç³»ç»Ÿ - å‘½ä»¤è¡Œäº¤äº’ç•Œé¢
åŠŸèƒ½ï¼šæä¾›ç”¨æˆ·å‹å¥½çš„å‘½ä»¤è¡Œäº¤äº’ä½“éªŒ
"""

import os
import sys
import json
import logging
from typing import List, Dict
from pathlib import Path

logging.basicConfig(level=logging. INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from retrieval_module import HybridRetriever
    from generation_module import RAGGenerator, PromptBuilder
except ImportError:
    logger.error("ç¼ºå°‘å¿…è¦çš„æ¨¡å—æ–‡ä»¶")
    sys.exit(1)


class RAGCLI:
    """RAGç³»ç»Ÿå‘½ä»¤è¡Œäº¤äº’ç•Œé¢"""
    
    def __init__(self, chunks_file: str = "preprocessed_data/chunks.json"):
        """
        åˆå§‹åŒ–CLI
        
        Args:
            chunks_file: é¢„å¤„ç†åçš„åˆ†å—æ–‡ä»¶è·¯å¾„
        """
        self. chunks_file = chunks_file
        self.chunks = None
        self.retriever = None
        self.generator = None
        self.conversation_history = []
        
        logger.info("åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        self._initialize_system()
    
    def _initialize_system(self):
        """åˆå§‹åŒ–ç³»ç»Ÿï¼šåŠ è½½åˆ†å—ã€åˆå§‹åŒ–æ£€ç´¢å™¨å’Œç”Ÿæˆå™¨"""
        
        # æ­¥éª¤1ï¼šåŠ è½½åˆ†å—
        if not os.path.exists(self. chunks_file):
            logger. error(f"æœªæ‰¾åˆ°åˆ†å—æ–‡ä»¶: {self.chunks_file}")
            logger.info("è¯·å…ˆè¿è¡Œ data_preprocessing.py è¿›è¡Œæ•°æ®é¢„å¤„ç†")
            sys.exit(1)
        
        logger.info(f"åŠ è½½åˆ†å—æ–‡ä»¶: {self.chunks_file}")
        with open(self.chunks_file, 'r', encoding='utf-8') as f:
            self.chunks = json.load(f)
        logger.info(f"æˆåŠŸåŠ è½½ {len(self.chunks)} ä¸ªåˆ†å—")
        
        # æ­¥éª¤2ï¼šåˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
        logger.info("åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨...")
        try:
            # ä½¿ç”¨Hugging Faceé•œåƒä¸­çš„æ¨¡å‹
            model_name = "BAAI/bge-m3"
            self.retriever = HybridRetriever(
                self.chunks,
                model_name=model_name,
                use_gpu=True
            )
            logger.info("æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ£€ç´¢å™¨å¤±è´¥: {e}")
            logger.info("å°è¯•åœ¨CPUæ¨¡å¼ä¸‹ç»§ç»­...")
            try:
                self.retriever = HybridRetriever(
                    self.chunks,
                    model_name=model_name,
                    use_gpu=False
                )
            except Exception as e2:
                logger.error(f"CPUæ¨¡å¼ä¹Ÿå¤±è´¥äº†: {e2}")
                sys.exit(1)
        
        # æ­¥éª¤3ï¼šåˆå§‹åŒ–ç”Ÿæˆå™¨
        logger.info("åˆå§‹åŒ–ç”Ÿæˆå™¨...")
        try:
            self.generator = RAGGenerator(
                use_api=True,
                api_url=os.getenv("OPENAI_API_URL"),
                api_key=os.getenv("OPENAI_API_KEY"),
                model="gpt-5-mini" #ä¿®æ”¹æ¨¡å‹åç§°ä¸ºgpt-5-mini
            )
            logger.info("ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–ç”Ÿæˆå™¨å¤±è´¥: {e}")
            sys.exit(1)
        
        logger.info("\nâœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼\n")
    
    def _print_banner(self):
        """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
        banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   æµ·æ´‹æ¸”ä¸šè°ˆåˆ¤è¾…åŠ©RAGç³»ç»Ÿ                                  â•‘
â•‘   Fishery Negotiation Assistance RAG System                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ä½¿ç”¨è¯´æ˜ï¼š
  â€¢ è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¿›è¡Œæ£€ç´¢å’Œç”Ÿæˆç­”æ¡ˆ
  â€¢ è¾“å…¥ 'help'   æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯
  â€¢ è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²
  â€¢ è¾“å…¥ 'exit'   é€€å‡ºç³»ç»Ÿ
  â€¢ è¾“å…¥ 'save'   ä¿å­˜å¯¹è¯å†å²

"""
        print(banner)
    
    def _print_help(self):
        """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
        help_text = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€å‘½ä»¤åˆ—è¡¨ã€‘

1. è¾“å…¥é—®é¢˜ (ç›´æ¥è¾“å…¥ä¸­æ–‡æˆ–è‹±æ–‡é—®é¢˜)
   ç¤ºä¾‹: è‹¥æ¸”èˆ¹åœ¨ä¸œå¤ªå¹³æ´‹å› ä¸å¯æŠ—åŠ›åŸå› æœªèƒ½éµå®ˆç¦æ¸”æœŸï¼Œæ˜¯å¦å¯ä»¥ç”³è¯·è±å…ï¼Ÿ

2. help
   æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

3.  history
   æ˜¾ç¤ºæœ€è¿‘çš„å¯¹è¯å†å²

4. retrieve <é—®é¢˜æ–‡æœ¬>
   ä»…æ‰§è¡Œæ£€ç´¢ï¼Œä¸ç”Ÿæˆç­”æ¡ˆ
   ç¤ºä¾‹: retrieve ç¦æ¸”æœŸçš„å®šä¹‰

5. analyze <é—®é¢˜æ–‡æœ¬>
   æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹çš„è¯¦ç»†åˆ†æ

6. save
   å°†å¯¹è¯å†å²ä¿å­˜ä¸ºJSONæ–‡ä»¶

7. clear
   æ¸…ç©ºå¯¹è¯å†å²

8. exit (æˆ– quit, q)
   é€€å‡ºç³»ç»Ÿ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        print(help_text)
    
    def _print_section(self, title: str, content: str = ""):
        """æ‰“å°æ ¼å¼åŒ–çš„ç« èŠ‚"""
        print(f"\nã€{title}ã€‘")
        if content:
            print(content)
    
    def retrieve_and_display(self, question: str, show_details: bool = False):
        """
        æ‰§è¡Œæ£€ç´¢å¹¶æ˜¾ç¤ºç»“æœ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†åˆ†æ
        """
        self._print_section("æ£€ç´¢è¿‡ç¨‹")
        print(f"é—®é¢˜: {question}\n")
        
        try:
            results = self.retriever.retrieve(question, top_k=5)
            
            print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³åˆ†å—:\n")
            
            for i, chunk in enumerate(results, 1):
                source = chunk["metadata"]. get("source_document", "Unknown")
                clause = chunk["metadata"].get("clause_number", "N/A")
                score = chunk. get("score", 0)
                text_preview = chunk["text"][:150] + "..." if len(chunk["text"]) > 150 else chunk["text"]
                
                print(f"  [{i}] åŒ¹é…åº¦: {score:.1%}")
                print(f"      æ¥æº: {source}")
                print(f"      æ¡æ¬¾: {clause}")
                print(f"      æ–‡æœ¬: {text_preview}\n")
            
            if show_details:
                self._print_section("è¯¦ç»†åˆ†æ", "è¿™æ˜¯å®Œæ•´çš„æ£€ç´¢ç»“æœåˆ†æ")
            
            return results
            
        except Exception as e:
            logger.error(f"æ£€ç´¢å¤±è´¥: {e}")
            print(f"âœ— æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def generate_answer(self, question: str, retrieved_chunks: List[Dict]):
        """
        ç”Ÿæˆç­”æ¡ˆå¹¶æ˜¾ç¤º
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            retrieved_chunks: æ£€ç´¢åˆ°çš„åˆ†å—
        """
        self._print_section("ç­”æ¡ˆç”Ÿæˆ")
        print("æ­£åœ¨è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆç­”æ¡ˆ.. .\n")
        
        try:
            result = self.generator.generate_answer(question, retrieved_chunks)
            
            # æ˜¾ç¤ºç­”æ¡ˆ
            self._print_section("æœ€ç»ˆç­”æ¡ˆ")
            print(result["answer"])
            
            # ä¿å­˜åˆ°å¯¹è¯å†å²
            self.conversation_history.append({
                "question": question,
                "answer": result["answer"],
                "retrieved_chunks_count": len(retrieved_chunks),
                "timestamp": self._get_timestamp()
            })
            
            return result
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            print(f"âœ— ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            return None
    
    def process_question(self, question: str):
        """
        å¤„ç†ç”¨æˆ·é—®é¢˜çš„å®Œæ•´æµç¨‹ï¼šæ£€ç´¢ -> ç”Ÿæˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
        """
        # æ£€ç´¢
        retrieved_chunks = self.retrieve_and_display(question)
        
        if not retrieved_chunks:
            print("âœ— æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆ")
            return
        
        # ç”Ÿæˆ
        self.generate_answer(question, retrieved_chunks)
    
    def show_history(self, limit: int = 5):
        """æ˜¾ç¤ºå¯¹è¯å†å²"""
        if not self.conversation_history:
            print("è¿˜æ²¡æœ‰å¯¹è¯å†å²")
            return
        
        self._print_section("å¯¹è¯å†å²")
        recent = self.conversation_history[-limit:]
        
        for i, item in enumerate(recent, 1):
            print(f"\n[{i}] {item['timestamp']}")
            print(f"    é—®é¢˜: {item['question'][:80]}...")
            print(f"    æ£€ç´¢åˆ†å—æ•°: {item['retrieved_chunks_count']}")
    
    def save_history(self, output_file: str = "conversation_history.json"):
        """ä¿å­˜å¯¹è¯å†å²"""
        os.makedirs("output", exist_ok=True)
        output_path = os.path.join("output", output_file)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)
        
        print(f"âœ“ å¯¹è¯å†å²å·²ä¿å­˜åˆ°: {output_path}")
    
    @staticmethod
    def _get_timestamp() -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime. now().strftime("%Y-%m-%d %H:%M:%S")
    
    def run(self):
        """å¯åŠ¨äº¤äº’å¼CLI"""
        self._print_banner()
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ“ è¾“å…¥é—®é¢˜ (è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©): ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†å‘½ä»¤
                if user_input. lower() in ['exit', 'quit', 'q']:
                    print("\nå†è§ï¼")
                    break
                
                elif user_input.lower() == 'help':
                    self._print_help()
                
                elif user_input.lower() == 'history':
                    self.show_history()
                
                elif user_input.lower() == 'save':
                    self.save_history()
                
                elif user_input.lower() == 'clear':
                    self.conversation_history = []
                    print("âœ“ å¯¹è¯å†å²å·²æ¸…ç©º")
                
                elif user_input.lower(). startswith('retrieve '):
                    question = user_input[9:].strip()
                    if question:
                        self.retrieve_and_display(question)
                    else:
                        print("âœ— è¯·æä¾›é—®é¢˜æ–‡æœ¬")
                
                elif user_input.lower().startswith('analyze '):
                    question = user_input[8:].strip()
                    if question:
                        self.retrieve_and_display(question, show_details=True)
                    else:
                        print("âœ— è¯·æä¾›é—®é¢˜æ–‡æœ¬")
                
                else:
                    # æ™®é€šé—®é¢˜
                    self.process_question(user_input)
            
            except KeyboardInterrupt:
                print("\n\nå†è§ï¼")
                break
            except Exception as e:
                logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}")
                print(f"âœ— å‡ºé”™: {e}")


# ============ ä¸»ç¨‹åºå…¥å£ ============
if __name__ == "__main__":
    try:
        # è®¾ç½®Hugging Faceé•œåƒåœ°å€
        # è¿™ä¼šè®©sentence-transformersåº“é€šè¿‡é•œåƒä¸‹è½½æ¨¡å‹
        os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
        
        cli = RAGCLI()
        cli.run()
    except Exception as e:
        logger.error(f"å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)